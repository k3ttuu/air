# -*- coding: utf-8 -*-
"""Bump Buddy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XFvRXNfC4Tf0g5casGvn9sqobaXkDGdv
"""



"""Installations"""

!pip install sentencepiece #library for text tokenization

!pip install -q bitsandbytes #library for loading and managing models

!pip install -q transformers torch accelerate #libraries for working with HF models and Pytorch

!pip install -q --upgrade gradio

!pip install --upgrade tensorflow

"""Teachable Machine Model"""

import numpy as np
import tensorflow as tf
from PIL import Image
import gradio as gr

# Download TensorFlow Lite model from Teachable Machine and upload on Colab
# Copy the file path
# Using TensorFlow Lite as focuses on inferencing, runs faster and is more efficient
# Reference: https://stackshare.io/stackups/tensorflow-js-vs-tensorflow-lite#:~:text=js%20provides%20a%20comprehensive%20set,API%20support%20for%20training%20models.
interpreter = tf.lite.Interpreter(model_path='/model_unquant.tflite')
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Load the type of damage from labels.txt
with open('/labels (1).txt', 'r') as f:
    damage_labels = [line.strip() for line in f]


def preprocess_image(image_path):
    # Open the image
    img = Image.open(image_path)

    # Resizing the image as there may difference in processing images during model conversion, which causes accuracy errors
    # Reference: https://stackoverflow.com/questions/16646183/crop-an-image-in-the-centre-using-pil
    # Reference: https://colab.research.google.com/drive/1DJ-OPXE9ARaPLa-gwJAxdTjUCO44PHpS?usp=sharing
    width, height = img.size
    if width > height:
        left = (width - height) / 2
        right = left + height
        img = img.crop((left, 0, right, height))
    else:
        top = (height - width) / 2
        bottom = top + width
        img = img.crop((0, top, width, bottom))

    img = img.resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = img_array.astype(np.float32)
    img_array = np.expand_dims(img_array, axis=0)

    return img_array

# Detecting the type of damage. Only one image is used for this prototype as it provides a detailed analysis.
# Hence, we focus on only 1 image to prevent confusion.
def detect_damage(image_path):
    img_array = preprocess_image(image_path)
    interpreter.set_tensor(input_details[0]['index'], img_array)
    interpreter.invoke()
    predictions = interpreter.get_tensor(output_details[0]['index'])[0]
    damage_type_idx = np.argmax(predictions)
    damage_type = damage_labels[damage_type_idx]

    print(f"Detected damage type: '{damage_type}'")

    # If there is no damage, explicitly check for "Car is ok" and other wordings
    if damage_type.lower() in ["car is ok", "5 car is ok", "ok"]:
        return None  # Return None if there is no damage detected

    return damage_type  # Return the actual damage type if there is a damage.

"""Chatbot"""

def chatbot_response(damage_type, car_plate, location):
# Include link for Hyperlink on 'FAQ page'
    return (
        f"Thank you for reporting the damage: {damage_type}.\n\n"
        f"Our team will review it and get back to you.\n\n"
        f"Car Plate: {car_plate}, Location: {location}.\n\n"
        "For more information, visit our [FAQ page](https://help.getgo.sg/hc/en-us/sections/28229450198553-Vehicle-Damages)."
    )

"""Creating different Pages

"""

with gr.Blocks() as app:
    # Page 1: Initial Photo Capture Page
    with gr.Row(visible=True) as page1:
        gr.Markdown("# BUMPBUDDY Car Damage Detection")
        image_input = gr.Image("upload", label="Upload Car Photo", type="filepath")
        car_plate_input = gr.Textbox(label="Car Plate", value="")
        location_input = gr.Textbox(label="Location", value="")
        submit_button = gr.Button("Submit")

    # Page 2: Damage Reporting Page
    with gr.Row(visible=False) as page2:
        damage_output = gr.Textbox(label="Damage Analysis Result", interactive=False)
        report_button = gr.Button("Report Damage")
        retake_button = gr.Button("Retake Photo")

    # Page 3: Chatbot Response Page
    with gr.Row(visible=False) as page3:
        chatbot_output = gr.Markdown()
        lock_car_button3 = gr.Button("Lock Car")

    # Page 4: Thank You Page
    with gr.Row(visible=False) as page4:
        gr.Markdown("# There is no damage detected. You can lock the car.")
        lock_car_button4 = gr.Button("Lock Car")

    # Button actions
    def submit_action(image, car_plate, location):
        damage_type = detect_damage(image)
        print(f"submit_action: damage_type = {damage_type}")  # Debugging line

        if damage_type is not None:
            return (
                gr.update(visible=False),   # Hide Page 1
                gr.update(visible=True),    # Show Page 2
                gr.update(visible=False),   # Hide Page 3
                gr.update(visible=False),   # Hide Page 4
                damage_type                 # Update damage_output
            )
        else:
            return (
                gr.update(visible=False),   # Hide Page 1
                gr.update(visible=False),   # Hide Page 2
                gr.update(visible=False),   # Hide Page 3
                gr.update(visible=True),    # Show Page 4
                ""                          # Clear damage_output
            )

    def report_damage_action(damage_output, car_plate, location):
        chatbot_text = chatbot_response(damage_output, car_plate, location)
        return gr.update(visible=False), gr.update(visible=True), chatbot_text

    def retake_photo_action():
        return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False),

    # Page transitions
    submit_button.click(
        submit_action,
        inputs=[image_input, car_plate_input, location_input],
        outputs=[page1, page2, page3, page4, damage_output]
    )
    report_button.click(
        report_damage_action,
        inputs=[damage_output, car_plate_input, location_input],
        outputs=[page2, page3, chatbot_output]
    )
    retake_button.click(
        retake_photo_action,
        outputs=[page1, page2, page3, page4]
    )

    lock_car_button3.click(
        outputs=[page1, page2, page3, page4]
    )

app.launch()